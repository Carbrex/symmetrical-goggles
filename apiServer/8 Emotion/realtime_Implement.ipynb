{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MeidanGR/SpeechEmotionRecognition_Realtime/blob/main/3_realtime_ser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "lA4vLC6ID715"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install pydub\n",
        "%pip install noisereduce\n",
        "%pip install pyaudio\n",
        "%pip install json-tricks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V4cVP0NmD71-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-06 21:29:58.324658: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-06 21:30:00.445328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "import os\n",
        "from json_tricks import load\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import librosa\n",
        "from pydub import AudioSegment, effects\n",
        "import noisereduce as nr\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSjs9TReEUls"
      },
      "source": [
        "# **LOAD MODEL**\n",
        "Loading the speech emotion recognition LSTM model and weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6qXd1-vD72A",
        "outputId": "9a687758-6391-4ec5-ec83-e52bb0f5ffc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-06 21:30:03.097678: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:03.107241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:03.107690: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:03.111642: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:03.112180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:03.112547: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:08.208461: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:08.209938: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:08.211049: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-06 21:30:08.219132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2247 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1650, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 339, 64)           20480     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 8)                 520       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 54024 (211.03 KB)\n",
            "Trainable params: 54024 (211.03 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "saved_model_path = './model8723.json'\n",
        "saved_weights_path = './model8723_weights.h5'\n",
        "\n",
        "#Reading the model from JSON file\n",
        "with open(saved_model_path, 'r') as json_file:\n",
        "    json_savedModel = json_file.read()\n",
        "    \n",
        "# Loading the model architecture, weights\n",
        "model = tf.keras.models.model_from_json(json_savedModel)\n",
        "model.load_weights(saved_weights_path)\n",
        "\n",
        "# Compiling the model with similar parameters as the original model.\n",
        "model.compile(loss='categorical_crossentropy', \n",
        "                optimizer='RMSProp', \n",
        "                metrics=['categorical_accuracy'])\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WyCwGZaeD72C"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path, frame_length = 2048, hop_length = 512):\n",
        "    '''\n",
        "    A process to an audio .wav file before execcuting a prediction.\n",
        "      Arguments:\n",
        "      - file_path - The system path to the audio file.\n",
        "      - frame_length - Length of the frame over which to compute the speech features. default: 2048\n",
        "      - hop_length - Number of samples to advance for each frame. default: 512\n",
        "\n",
        "      Return:\n",
        "        'X_3D' variable, containing a shape of: (batch, timesteps, feature) for a single file (batch = 1).\n",
        "    ''' \n",
        "    # Fetch sample rate.\n",
        "    _, sr = librosa.load(path = file_path, sr = None)\n",
        "    # Load audio file\n",
        "    rawsound = AudioSegment.from_file(file_path, duration = None) \n",
        "    # Normalize to 5 dBFS \n",
        "    normalizedsound = effects.normalize(rawsound, headroom = 5.0) \n",
        "    # Transform the audio file to np.array of samples\n",
        "    normal_x = np.array(normalizedsound.get_array_of_samples(), dtype = 'float32') \n",
        "    # Noise reduction                  \n",
        "    final_x = nr.reduce_noise(normal_x, sr=sr)\n",
        "        \n",
        "        \n",
        "    f1 = librosa.feature.rms(y=final_x, frame_length=frame_length, hop_length=hop_length, center=True, pad_mode='reflect').T # Energy - Root Mean Square\n",
        "    f2 = librosa.feature.zero_crossing_rate(final_x, frame_length=frame_length, hop_length=hop_length,center=True).T # ZCR\n",
        "    f3 = librosa.feature.mfcc(y=final_x, sr=sr, S=None, n_mfcc=13, hop_length = hop_length).T # MFCC   \n",
        "    X = np.concatenate((f1, f2, f3), axis = 1)\n",
        "    \n",
        "    X_3D = np.expand_dims(X, axis=0)\n",
        "    \n",
        "    return X_3D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vXfNZp8qD72D"
      },
      "outputs": [],
      "source": [
        "# Emotions list is created for a readable form of the model prediction.\n",
        "\n",
        "emotions = {\n",
        "    0 : 'neutral',\n",
        "    1 : 'calm',\n",
        "    2 : 'happy',\n",
        "    3 : 'sad',\n",
        "    4 : 'angry',\n",
        "    5 : 'fearful',\n",
        "    6 : 'disgust',\n",
        "    7 : 'suprised'   \n",
        "}\n",
        "emo_list = list(emotions.values())\n",
        "\n",
        "def is_silent(data):\n",
        "    # Returns 'True' if below the 'silent' threshold\n",
        "    return max(data) < 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4s4DyZckD72E",
        "outputId": "862921df-ad36-4b23-9532-81762f128793"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ALSA lib pcm_dsnoop.c:566:(snd_pcm_dsnoop_open) unable to open slave\n",
            "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.rear\n",
            "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.center_lfe\n",
            "ALSA lib pcm.c:2675:(snd_pcm_open_noupdate) Unknown PCM cards.pcm.side\n",
            "ALSA lib pcm_route.c:878:(find_matching_chmap) Found no matching channel map\n",
            "ALSA lib pcm_route.c:878:(find_matching_chmap) Found no matching channel map\n",
            "ALSA lib pcm_route.c:878:(find_matching_chmap) Found no matching channel map\n",
            "Cannot connect to server socket err = No such file or directory\n",
            "Cannot connect to server request channel\n",
            "jack server is not running or cannot be started\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
            "Cannot connect to server socket err = No such file or directory\n",
            "Cannot connect to server request channel\n",
            "jack server is not running or cannot be started\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
            "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
            "ALSA lib pcm_oss.c:397:(_snd_pcm_oss_open) Cannot open device /dev/dsp\n",
            "ALSA lib dlmisc.c:339:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_a52.so (/home/histox/miniconda3/envs/speechRealtime/lib/python3.9/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /lib/x86_64-linux-gnu/libjxl_threads.so.0.7))\n",
            "ALSA lib dlmisc.c:339:(snd_dlobj_cache_get0) Cannot open shared library libasound_module_pcm_a52.so (/home/histox/miniconda3/envs/speechRealtime/lib/python3.9/site-packages/zmq/backend/cython/../../../../.././libstdc++.so.6: version `GLIBCXX_3.4.30' not found (required by /lib/x86_64-linux-gnu/libjxl_threads.so.0.7))\n",
            "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
            "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
            "ALSA lib confmisc.c:160:(snd_config_get_card) Invalid field card\n",
            "ALSA lib pcm_usb_stream.c:482:(_snd_pcm_usb_stream_open) Invalid card 'card'\n",
            "Cannot connect to server socket err = No such file or directory\n",
            "Cannot connect to server request channel\n",
            "jack server is not running or cannot be started\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n",
            "JackShmReadWritePtr::~JackShmReadWritePtr - Init not done for -1, skipping unlock\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "** session started\n",
            "* recording...\n",
            "* done recording\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/histox/miniconda3/envs/speechRealtime/lib/python3.9/site-packages/noisereduce/spectralgate/nonstationary.py:71: RuntimeWarning: invalid value encountered in divide\n",
            "  sig_mult_above_thresh = (abs_sig_stft - sig_stft_smooth) / sig_stft_smooth\n"
          ]
        },
        {
          "ename": "ParameterError",
          "evalue": "Audio buffer is not finite everywhere",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mParameterError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8 Emotion/realtime_Implement.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     wf\u001b[39m.\u001b[39mwriteframes(\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(frames))\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m* done recording\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m x \u001b[39m=\u001b[39m preprocess(WAVE_OUTPUT_FILE) \u001b[39m# 'output.wav' file preprocessing.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m \u001b[39m# Model's prediction => an 8 emotion probabilities array.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(x, use_multiprocessing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "\u001b[1;32m/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8 Emotion/realtime_Implement.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m final_x \u001b[39m=\u001b[39m nr\u001b[39m.\u001b[39mreduce_noise(normal_x, sr\u001b[39m=\u001b[39msr)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m f1 \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mrms(y\u001b[39m=\u001b[39mfinal_x, frame_length\u001b[39m=\u001b[39mframe_length, hop_length\u001b[39m=\u001b[39mhop_length, center\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, pad_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mreflect\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mT \u001b[39m# Energy - Root Mean Square\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m f2 \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39;49mfeature\u001b[39m.\u001b[39;49mzero_crossing_rate(final_x, frame_length\u001b[39m=\u001b[39;49mframe_length, hop_length\u001b[39m=\u001b[39;49mhop_length,center\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mT \u001b[39m# ZCR\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m f3 \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mfeature\u001b[39m.\u001b[39mmfcc(y\u001b[39m=\u001b[39mfinal_x, sr\u001b[39m=\u001b[39msr, S\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, n_mfcc\u001b[39m=\u001b[39m\u001b[39m13\u001b[39m, hop_length \u001b[39m=\u001b[39m hop_length)\u001b[39m.\u001b[39mT \u001b[39m# MFCC   \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/histox/LinuxFiles/Files/symmetrical-goggles/apiServer/8%20Emotion/realtime_Implement.ipynb#X10sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((f1, f2, f3), axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/speechRealtime/lib/python3.9/site-packages/librosa/feature/spectral.py:1111\u001b[0m, in \u001b[0;36mzero_crossing_rate\u001b[0;34m(y, frame_length, hop_length, center, **kwargs)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute the zero-crossing rate of an audio time series.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \n\u001b[1;32m   1066\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[39marray([[0.044, 0.074, ..., 0.488, 0.355]])\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1110\u001b[0m \u001b[39m# check if audio is valid\u001b[39;00m\n\u001b[0;32m-> 1111\u001b[0m util\u001b[39m.\u001b[39;49mvalid_audio(y, mono\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m   1113\u001b[0m \u001b[39mif\u001b[39;00m center:\n\u001b[1;32m   1114\u001b[0m     padding \u001b[39m=\u001b[39m [(\u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m) \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(y\u001b[39m.\u001b[39mndim)]\n",
            "File \u001b[0;32m~/miniconda3/envs/speechRealtime/lib/python3.9/site-packages/librosa/util/utils.py:314\u001b[0m, in \u001b[0;36mvalid_audio\u001b[0;34m(y, mono)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[39mraise\u001b[39;00m ParameterError(\n\u001b[1;32m    310\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid shape for monophonic audio: ndim=\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mndim\u001b[39m:\u001b[39;00m\u001b[39md\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m, shape=\u001b[39m\u001b[39m{\u001b[39;00my\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m     )\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(y)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mraise\u001b[39;00m ParameterError(\u001b[39m\"\u001b[39m\u001b[39mAudio buffer is not finite everywhere\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    316\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mParameterError\u001b[0m: Audio buffer is not finite everywhere"
          ]
        }
      ],
      "source": [
        "import pyaudio\n",
        "import wave\n",
        "from array import array\n",
        "import struct\n",
        "import time\n",
        "\n",
        "# Initialize variables\n",
        "RATE = 24414\n",
        "CHUNK = 512\n",
        "RECORD_SECONDS = 7.1\n",
        "\n",
        "FORMAT = pyaudio.paInt32\n",
        "CHANNELS = 1\n",
        "WAVE_OUTPUT_FILE = \"./output.wav\"\n",
        "\n",
        "# Open an input channel\n",
        "p = pyaudio.PyAudio()\n",
        "stream = p.open(format=FORMAT,\n",
        "                channels=CHANNELS,\n",
        "                rate=RATE,\n",
        "                input=True,\n",
        "                frames_per_buffer=CHUNK)\n",
        "\n",
        "\n",
        "# Initialize a non-silent signals array to state \"True\" in the first 'while' iteration.\n",
        "data = array('h', np.random.randint(size = 512, low = 0, high = 500))\n",
        "\n",
        "# SESSION START\n",
        "print(\"** session started\")\n",
        "total_predictions = [] # A list for all predictions in the session.\n",
        "tic = time.perf_counter()\n",
        "\n",
        "while is_silent(data) == False:\n",
        "    print(\"* recording...\")\n",
        "    frames = [] \n",
        "    data = np.nan # Reset 'data' variable.\n",
        "\n",
        "    timesteps = int(RATE / CHUNK * RECORD_SECONDS) # => 339\n",
        "\n",
        "    # Insert frames to 'output.wav'.\n",
        "    for i in range(0, timesteps):\n",
        "        data = array('l', stream.read(CHUNK)) \n",
        "        frames.append(data)\n",
        "\n",
        "        wf = wave.open(WAVE_OUTPUT_FILE, 'wb')\n",
        "        wf.setnchannels(CHANNELS)\n",
        "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
        "        wf.setframerate(RATE)\n",
        "        wf.writeframes(b''.join(frames))\n",
        "\n",
        "    print(\"* done recording\")\n",
        "\n",
        "    x = preprocess(WAVE_OUTPUT_FILE) # 'output.wav' file preprocessing.\n",
        "    # Model's prediction => an 8 emotion probabilities array.\n",
        "    predictions = model.predict(x, use_multiprocessing=True)\n",
        "    pred_list = list(predictions)\n",
        "    pred_np = np.squeeze(np.array(pred_list).tolist(), axis=0) # Get rid of 'array' & 'dtype' statments.\n",
        "    total_predictions.append(pred_np)\n",
        "    \n",
        "    # Present emotion distribution for a sequence (7.1 secs).\n",
        "    fig = plt.figure(figsize = (10, 2))\n",
        "    plt.bar(emo_list, pred_np, color = 'darkturquoise')\n",
        "    plt.ylabel(\"Probabilty (%)\")\n",
        "    plt.show()\n",
        "    \n",
        "    max_emo = np.argmax(predictions)\n",
        "    print('max emotion:', emotions.get(max_emo,-1))\n",
        "    \n",
        "    print(100*'-')\n",
        "    \n",
        "    # Define the last 2 seconds sequence.\n",
        "    last_frames = np.array(struct.unpack(str(96 * CHUNK) + 'B' , np.stack(( frames[-1], frames[-2], frames[-3], frames[-4],\n",
        "                                                                            frames[-5], frames[-6], frames[-7], frames[-8],\n",
        "                                                                            frames[-9], frames[-10], frames[-11], frames[-12],\n",
        "                                                                            frames[-13], frames[-14], frames[-15], frames[-16],\n",
        "                                                                            frames[-17], frames[-18], frames[-19], frames[-20],\n",
        "                                                                            frames[-21], frames[-22], frames[-23], frames[-24]),\n",
        "                                                                            axis =0)) , dtype = 'b')\n",
        "    if is_silent(last_frames): # If the last 2 seconds are silent, end the session.\n",
        "        break\n",
        "\n",
        "# SESSION END        \n",
        "toc = time.perf_counter()\n",
        "stream.stop_stream()\n",
        "stream.close()\n",
        "p.terminate()\n",
        "wf.close()\n",
        "print('** session ended')\n",
        "\n",
        "# Present emotion distribution for the whole session.\n",
        "total_predictions_np =  np.mean(np.array(total_predictions).tolist(), axis=0)\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "plt.bar(emo_list, total_predictions_np, color = 'indigo')\n",
        "plt.ylabel(\"Mean probabilty (%)\")\n",
        "plt.title(\"Session Summary\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"Emotions analyzed for: {(toc - tic):0.4f} seconds\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "3_realtime_ser.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
